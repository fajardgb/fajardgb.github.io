<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Gabriel Fajardo</title>
    <link rel="icon" type="image/png" sizes="32x32" href="imgs/ai.png" />
    <link rel="stylesheet" href="style.css" />
  </head>
  <body>
    <!-- **************************** HEADER **************************** -->
    <header class="main-header">
      <nav class="nav main-nav">
        <div class="logo">
          <a href="#home">Gabriel Fajardo</a>
        </div>
        <ul>
          <!-- <li><a href="aboutme.html">About Me</a></li> -->
          <li><a href="#aboutme">About Me</a></li>
          <li><a href="#research">Research</a></li>
          <li><a href="#resources">Resources</a></li>
          <li><a href="#contact">Contact</a></li>
          <li><a href="imgs/GF_CV.pdf" target="_blank">CV</a></li>
        </ul>
      </nav>
    </header>
    <!-- **************************** MAIN **************************** -->
    <main id="home">
      <div>
        <img
          class="brain-img"
          src="imgs/gabe logo_transparent_bg.png"
          alt="Brains"
        />
      </div>
    </main>
    <!-- **************************** ABOUT ME **************************** -->
    <section id="aboutme" class="content-section container">
      <h2 class="section-header">About Me</h2>

      <div class="aboutme-content-section">
        <img src="imgs/headshot.png" alt="headshot" />
        <p>
          Hi! My name is Gabriel Fajardo, and I am the lab manager in the
          <a href="https://www.freemanlab.org/" target="_blank"
            >Social Cognitive and Neural Sciences Lab</a
          >
          at Columbia University (PI:
          <a href="https://www.jonbfreeman.com/" target="_blank"> Jon Freeman</a
          >). My research interests are at the intersection of social psychology
          and cognitive neuroscience, with an emphasis on computational
          approaches, or <strong>Computational Social Neuroscience</strong>.

          <br /><br />
          I aim to study the mechanisms through which the social brain
          efficiently and effortlessly makes sense of the rich, dynamic, and
          high-dimensional information from the social world. Additionally, I am
          interested in the difference between social and non-social perception. 

          <br /><br />
          I was born in Lima, Peru, but I moved to Montgomery, NJ (next to
          Princeton) when I was 6 years old. I graduated from Boston College in
          Spring 2023, where I worked in the
          <a href="https://sccnlab.bc.edu/" target="_blank"
            >Social and Cognitive Computational Neuroscience Lab</a
          >
          with Stefano Anzellotti. My research at BC utilized multivariate
          statistical dependence analyses based on neural networks (MVPN) to
          identify brain regions responsible for audio-visual integration.

          <br /><br />
          Outside of research, I enjoy soccer, films, and exploring NYC!
        </p>
      </div>
    </section>
    <!-- **************************** RESEARCH **************************** -->
    <section id="research" class="content-section container">
      <h2 class="section-header">Research</h2>

      <!--  Publications -->
      <h3 class="sub-header">Publications</h3>

      <p>
        <strong>Fajardo, G.</strong>, Fang, M., Anzellotti, S. (Under Review).
        <a href="imgs/paperMVPNinpress.pdf" target="_blank"
          >Distinct Brain Regions Combine Auditory Representations with
          Different Visual Streams.</a
        >
      </p>

      <br />

      <p>
        Prince, J.S., <strong>Fajardo, G.</strong>, Alvarez, G.A., Konkle, T.
        (May, 2024).
        <a href="imgs/paperICLR2024.pdf" target="_blank"
          >Manipulating dropout reveals an optimal balance of efficiency and
          robustness in biological and machine visual systems.</a
        >
        <em>International Conference on Learning Representations 2024</em>.
      </p>
      <br />

      <!--  Presentations -->
      <h3 class="sub-header">Presentations</h3>

      <div class="presentation-item">
        <p>
          <strong>Fajardo, G.</strong>, Chwe, J.A., Davachi, L., Freeman, J.
          (April, 2024).
          <em>The neural basis of social categorization and individuation.</em>
          Poster presented at the Social and Affective Neuroscience society
          annual conference, Toronto, Canada.
        </p>
        <img src="imgs/posterSANS2024.png" alt="posterSANS2024" />
      </div>

      <hr />

      <div class="presentation-item">
        <p>
          <strong>Fajardo, G.</strong>, Hong, Y., Freeman, J. (February, 2024).
          <em
            >The shared cognitive and neural mechanisms of trait concepts and
            facial stereotyping.</em
          >
          Poster presented at the Society for Personality and Social Psychology
          annual convention, San Diego, CA.
        </p>
        <img src="imgs/posterSPSP2024.png" alt="posterSPSP2024" />
      </div>

      <hr />

      <div class="presentation-item">
        <p>
          Prince, J.S., <strong>Fajardo, G.</strong>, Alvarez, G.A., Konkle, T.
          (August, 2023).
          <em
            >Dropout as a tool for understanding information distribution in
            human and machine visual systems.</em
          >
          Poster presented at the Cognitive Computational Neuroscience annual
          conference, Oxford, UK.
        </p>
        <img src="imgs/posterCCN2023.jpg" alt="posterCCN2023" />
      </div>

      <hr />

      <div class="presentation-item">
        <p>
          <strong>Fajardo, G.</strong>, Alvarez, G.A., Konkle, T., Prince, J.
          (July, 2022).
          <em
            >Artificial vision model features most predictive of neural
            data.</em
          >
          Poster presented at the Leadership Alliance National Symposium,
          Hartford, CT.
        </p>
        <img src="imgs/posterLANS2022.jpg" alt="posterLANS2022" />
      </div>
      <br />

      <!--  Ongoing Projects -->
      <h3 class="sub-header">Ongoing Projects</h3>

      <div class="ongoing-projects">
        <div class="project-item">
          <h4 class="project-title">High dimensional face-trait space</h4>
          <div class="content-section-img-right">
            <img src="imgs/traitshighdim.jpg" alt="traitshighdim" />
            <p>
              People form personality trait impressions from the glimpse of a
              face. Most of the work that tries to propose which specific traits
              are inferred from the face has relied on a relatively small set of
              white male faces and preselected trait words; however, recent work
              from Dr. Chujun Lin
              <a
                href="https://www.nature.com/articles/s41467-021-25500-y"
                target="_blank"
                >(2021)</a
              >
              impressively gathers (1) 100 trait words that are commonly used to
              describe faces, and (2) 100 facial stimuli that have maximum
              variability in facial structure. Using Dr. Lin's methods, we have
              created an expansive face dataset, diverse in both gender and
              race. We plan to analyze the neural representational structure of
              the face-trait space and the added influence of race & gender on
              facial stereotyping.
            </p>
          </div>
        </div>

        <div class="project-item">
          <h4 class="project-title">Race & emotion neural adaptation</h4>
          <div class="content-section-img-right">
            <img src="imgs/neuroemoadaptation.jpg" alt="neuroemoadaptation" />
            <p>
              In collaboration with Dr. Brent Hughes, we are following up on his
              prior research
              <a
                href="https://www.pnas.org/doi/abs/10.1073/pnas.1822084116"
                target="_blank"
                >(2019)</a
              >, which found that white participants showed a greater tendency
              to individuate white faces based on neural release from
              adaptation. In this new work, we will assess how emotional
              expressions, specifically anger and happiness, moderate this
              effect.
            </p>
          </div>
        </div>

        <div class="project-item">
          <h4 class="project-title">Neural person representations over time</h4>
          <div class="content-section-img-right">
            <img src="imgs/friends.jpg" alt="friends" />
            <p>
              Using an exciting dataset where six participants watched six
              seasons of the popular TV show <em>Friends</em> while undergoing
              fMRI scanning, we aim to explore how neural representations of the
              characters change over time, along with several other intriguing
              ideas.
            </p>
          </div>
        </div>

        <!-- <div class="project-item">
          <h4 class="project-title">
            Emergence of identity-related information vs. facial stereotypes
          </h4>
          <div class="content-section-img-right">
            <img src="imgs/facevidentity.jpg" alt="facevidentity" />
            <p>
              We would like to test when in the processing stream
              identity-related information emerges, and if / how this competes
              with facial stereotyping. Utilizing several paradigms from
              social-cognitive psychology, we aim to analyze how identity and
              facial stereotypes interact, and when we might move past facial
              stereotyping.
            </p>
          </div>
        </div> -->

        <!-- <div class="project-item">
          <h4 class="project-title">
            Modeling the emergence of trait attributions from faces
          </h4>
          <div class="content-section-img-right">
            <img src="imgs/traitscategoryspace.jpg" alt="traitscategoryspace" />
            <p>
              The mechanisms by which certain facial features give rise to
              specific trait impressions are not fully understood. Using the
              interactive action and competition
              <a href="https://github.com/acmiceli/IACModel" target="_blank"
                >(IAC)</a
              >
              model, we aim to analyze how specific facial features inhibit and
              exhibit the emergence of select traits.
            </p>
          </div>
        </div> -->
      </div>
    </section>

    <!-- **************************** RESOURCES **************************** -->
    <section id="resources" class="content-section container">
      <h2 class="section-header">Resources</h2>

      <!--  Predoc resources -->
      <h3 class="sub-header">Undergrad and Post-bac Opportunities</h3>
      <p>
        <a
          href="https://docs.google.com/document/d/17Vs0bX3TAjHJdHMOFhIaNyyNb_uMVhPA9_JD7v5F2iM/edit"
          target="_blank"
          >Summer research postings</a
        >
      </p>

      <p>
        <a
          href="https://docs.google.com/document/d/1SV8chVgR5LJEMjIki1zVyA0YSvO0pa7zjwFkatiWH8o/edit"
          target="_blank"
          >Post-bac, lab manager, and RA full-time paid postings</a
        >
      </p>

      <!--  Research Tools -->
      <h3 class="sub-header">Research tools</h3>

      <p>
        <a href="https://github.com/fajardgb/jsPsych-FreemanLab" target="_blank"
          >jsPsych templates</a
        >
      </p>

      <p>
        <a
          href="https://drive.google.com/drive/folders/1_WevOVA7SzG0CRR93xN0ErRyBadDrjln?usp=drive_link"
          target="_blank"
          >Freeman Lab Coding Bootcamp (summer 2024)</a
        >
      </p>

      <p>
        <a
          href="https://drive.google.com/drive/folders/1OvnOcR07F36umBbOz6UjAxSPPT8zGjMT?usp=drive_link"
          target="_blank"
          >Freeman Lab Intro to fMRI Bootcamp (summer 2024)</a
        >
      </p>

      <!--  Miscellaneous Tools -->
      <h3 class="sub-header">Miscellaneous</h3>

      <div class="content-section-img-left">
        <img src="imgs/letterboxd.png" alt="Letterboxd Watchlist" />
        <p>
          <a
            href="https://github.com/fajardgb/letterboxd-watchlist"
            target="_blank"
            >Letterboxd Joint Watchlist</a
          >
        </p>
      </div>

      <div class="content-section-img-left">
        <img src="imgs/fpl.png" alt="FPL" />
        <p>
          <a href="https://github.com/fajardgb/FPL-viz" target="_blank"
            >Fantasy Premier League visualizations</a
          >
        </p>
      </div>
    </section>

    <!-- **************************** CONTACT **************************** -->

    <section id="contact" class="content-section container">
      <h2 class="section-header">Contact</h2>
      <div class="contact-container">
        <div class="contact-icons">
          <a href="mailto:gjf2118@columbia.edu">
            <img class="icon" src="imgs/mail.png" alt="Email" />
          </a>
          <a href="https://github.com/fajardgb" target="_blank">
            <img class="icon" src="imgs/github.png" alt="GitHub" />
          </a>
          <a href="https://twitter.com/gjfajardo5" target="_blank">
            <img class="icon" src="imgs/twitter.png" alt="Twitter" />
          </a>
          <a
            href="https://bsky.app/profile/gabefajardo.bsky.social"
            target="_blank"
          >
            <img class="icon" src="imgs/bluesky.png" alt="Bluesky" />
          </a>
          <a
            href="https://scholar.google.com/citations?user=LQVstzwAAAAJ&hl=en&oi=ao"
            target="_blank"
          >
            <img
              class="icon"
              src="imgs/graduation-cap.png"
              alt="Google-Scholar"
            />
          </a>
          <a href="imgs/GF_CV.pdf" target="_blank">
            <img class="icon" src="imgs/cv.png" alt="CV" />
          </a>
        </div>
        <div class="contact-map">
          <iframe
            src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d6039.759492010026!2d-73.96312715879863!3d40.808636271498365!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x89c2f63e33de0fb1%3A0xd304c1defb8278!2sSchermerhorn%20Hall!5e0!3m2!1sen!2sus!4v1712297889813!5m2!1sen!2sus"
            width="600"
            height="450"
            style="border: 0"
            allowfullscreen=""
            loading="lazy"
            referrerpolicy="no-referrer-when-downgrade"
          ></iframe>
        </div>
      </div>
    </section>
  </body>
</html>
